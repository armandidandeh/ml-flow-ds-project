{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load snippet/default_notebook_setup.py\n",
    "## Not all libraries support reloads. This might break things\n",
    "#%reload_ext autoreload\n",
    "#%autoreload 2\n",
    "%load_ext dotenv\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jovyan')\n",
    "\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load snippet/default_spark.py\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Window, DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config('spark.jars.packages', 'ml.combust.mleap:mleap-spark-base_2.11:0.14.0,ml.combust.mleap:mleap-spark_2.11:0.14.0')\n",
    "    .config('spark.sql.execution.arrow.enabled', 'true')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "import mlflow.pyfunc\n",
    "\n",
    "from project.data import raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = raw.load_iris('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load serialised models\n",
    "\n",
    "We load \n",
    "\n",
    "1. the fitted spark feature pipeline. This model had been logged in the spark flavour and we can use it as is.\n",
    "1. the sklearn classification model. This model had been logged  in the python flavour. To use it for batch scoring with Spark we create an UDF to upload our model to Spark for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_pipeline_run_id = 'f3a735a824264043a7978ee1aa0230d6'\n",
    "feature_pipeline = mlflow.spark.load_model('runs:/{}/feature_pipeline'.format(feature_pipeline_run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_run_id = '9eb818da5f3d43848c9e105509b0a392'\n",
    "model_udf = mlflow.pyfunc.spark_udf(\n",
    "    spark=spark,\n",
    "    model_uri='runs:/{}/iris_classification'.format(model_run_id), \n",
    "    result_type='string'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Scoring\n",
    "\n",
    "The Spark feature pipeline returns a spark dense vector. We have to turn the vectors into arrays first to be able to access them as needed to pass the features to our classifier. It's important to check version compatibiity of PyArrow and PySpark, e.g. PySpark 2.4 only works with PyArrow <= 0.14.1\n",
    "\n",
    "With Mlflow 1.3 the created model udf expects features as individual arguments rather than as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2array_udf = F.udf(lambda x: x.toArray().tolist(), T.ArrayType(T.DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+---------------+--------------+-----------+-----------+\n",
      "|sepal_length_cm|sepal_width_cm|petal_length_cm|petal_width_cm|      class| prediction|\n",
      "+---------------+--------------+---------------+--------------+-----------+-----------+\n",
      "|            5.1|           3.5|            1.4|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            4.9|           3.0|            1.4|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            4.7|           3.2|            1.3|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            4.6|           3.1|            1.5|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            5.0|           3.6|            1.4|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            5.4|           3.9|            1.7|           0.4|Iris-setosa|Iris-setosa|\n",
      "|            4.6|           3.4|            1.4|           0.3|Iris-setosa|Iris-setosa|\n",
      "|            5.0|           3.4|            1.5|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            4.4|           2.9|            1.4|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            4.9|           3.1|            1.5|           0.1|Iris-setosa|Iris-setosa|\n",
      "|            5.4|           3.7|            1.5|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            4.8|           3.4|            1.6|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            4.8|           3.0|            1.4|           0.1|Iris-setosa|Iris-setosa|\n",
      "|            4.3|           3.0|            1.1|           0.1|Iris-setosa|Iris-setosa|\n",
      "|            5.8|           4.0|            1.2|           0.2|Iris-setosa|Iris-setosa|\n",
      "|            5.7|           4.4|            1.5|           0.4|Iris-setosa|Iris-setosa|\n",
      "|            5.4|           3.9|            1.3|           0.4|Iris-setosa|Iris-setosa|\n",
      "|            5.1|           3.5|            1.4|           0.3|Iris-setosa|Iris-setosa|\n",
      "|            5.7|           3.8|            1.7|           0.3|Iris-setosa|Iris-setosa|\n",
      "|            5.1|           3.8|            1.5|           0.3|Iris-setosa|Iris-setosa|\n",
      "+---------------+--------------+---------------+--------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    feature_pipeline.transform(iris_df)\n",
    "    .withColumn('polyFeatureArray', vec2array_udf(F.col('polyFeatures')))\n",
    "    .withColumn('prediction', model_udf(\n",
    "        *map(lambda i: F.col('polyFeatureArray').getItem(i), range(34)))\n",
    "    )\n",
    "    .select('sepal_length_cm', 'sepal_width_cm', 'petal_length_cm', 'petal_width_cm', 'class', 'prediction')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
